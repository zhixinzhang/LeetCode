我用了MQ 有一个followup是如何来控制需要多少了consumers
问了如何来实现auto retry如果一个job failed了
问了如果某一个时间段 有很多jobs 需要怎么处理
问了如果在sch‍‌‌‌‌‍‌‌‍‍‌‌‍‌‌‍‌‍‌edule的时候需要保证high concurrency 怎么处理
比如说job dispatcher 挂了怎么办？
1. job dispatcher 有主从备份
2. job dispatcher 有sharding 如果挂了用类似consistent hashing的方式接管别的任务分发
问如果一个任务被执行多次怎么办？
1.要确保worker idempotent， 在任务前查库或者有fancy token的方式来确保不会重复提交

1. Before we jump to the high level design, please let me clarify the requirements and what features do we need

We need to design a job/task scheduler system. For this system we can create/schedule a task
and also we can delete and check the job status. If one job fail or success get notification
Other than that we can check job running history,view logs
1. Do we have concurrent job, repeating job (Crontab to mark the trigger time)?
2. SLA (long time withougt results)?

That the function requirements for the system.
Let we think about the non requirements. 
Non-Req : keep the system high avaiablility,  saclable, fault tolerance, consistency

That's the function and non-function for our system, do I missed anything? 

Cool, Before we go to design part, we can do a simple calualtion for the system throughput and DB storage

Estimation cost
1. , we can talk about how many jobs that we have every day and
how large DB storage we need to support to store job data
1000 M Job /per day -> 100M / 100K sec -> 10K QPS / per sec
It's a pretty large number, for this high QPS one host machine definitely cannot handle.
We need to split those requests to our backend service. (Distributed system)
4 core one machine and one core have 16 threads -> 1000 / 4 * 16 = 20 machines
1. one Job -> 1MB  one 100M job * 1MB = 100GB per day ->  100GB * 30 30TB

AWS for design. 

I would like to talk about what DB we should choose for the whole system.
Based on our discussion, that the backend database shoule be horizontally scalable as the job grows quickly(1000M a day)
In our user case, complex relational queries are not used. Most data access can be described as primary-key queries (e.g. given a job ID, get all executions). 
Also, the issues of strong consistency and transactions are not of paramount importance.
both sharded SQL and NoSQL databases can handle all the requirements of the system as long as they 
are tuned for reads. For simplicity, I'm going to use dynamodb in here. 

If our MySQL Database starts to grow too large, we might consider only storing a limited time period of data in the database, 
while storing the rest in a data warehouse such as Redshift
A data warehouse such as Redshift can comfortably handle the constraint of 1 TB of new content per month

1. our system mainly need to store Job information and like we discussed before 
the 



We use Message Queue in here. 
Be able to scale the consumer and producer nodes independently (in Kafka we have Topics which can be 
horizontally partitioned and scale by that)
We decouple the consumer and producer from each other
Lower latency for the producer (doesn't have to wait for a response)
Durability and Reliability: When a Consumer Node crashes another Node can process the Message 
which otherwise would be lost (see Offset in Kafka). The Messages are persisted.

Amazon SNS with SQS is called fanout pattern. In this pattern, a message published to an SNS topic is 
distributed to multiple SQS queues in parallel and SQS queue assure persistence, because SQS has retention
 policy. It can persist message up to 14 days(defult 4 days).
 Amazon SQS with SNS can achieved highly throughput parallel streaming and can replace Apache Kafka.

The benefit for Message Queues
Message queues enable asynchronous communication. Producers can add requests to the queue without waiting for them to be processed. 
Consumers process messages only when they are available. No component in the system is ever stalled waiting for another, optimizing data flow.
Queues make your data persistent, and reduce the errors that happen when different parts of your system go offline
Message queues make it possible to scale precisely where you need to


this is really low operation this is only going to run like once a minute or
55:08
something and it's just going to a single key range query so that's it's
55:13
not it's not even a full service it's just a Lambda function or a uh so you can you can set up ews Lambda
55:20
to um be triggered by a uh time just like a
55:25
Cron job and so that's what I envisioned for this thing um I think I already brought up that

DB (But yes, having a synchronous slave reduces the availability a bit. We shift from AP (CAP theorem) to CP a bit so it is a trade-off.)